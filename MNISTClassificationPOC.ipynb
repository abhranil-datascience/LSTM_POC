{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTClassificationPOC.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhranil-datascience/LSTM_POC/blob/master/MNISTClassificationPOC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_XzbUvGbeCs",
        "colab_type": "code",
        "outputId": "945ab726-92d9-4237-89e5-07374c192875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2418
        }
      },
      "source": [
        "############################## Mount Drive ######################################## \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "############################## Change Directory ###################################\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/MLandDLFullCourse/DL/AdvancedNLP/2.BidirectionalRNN')\n",
        "BestClassiferModel=\"BestClassiferModelLSTM.hdf5\"\n",
        "###################### Convert Digits to 28 x 28 matrix ###################\n",
        "def CreateMNISTDigitsMatrix(DigitDataset):\n",
        "  import numpy as np\n",
        "  DigitDataset=DigitDataset/255.0\n",
        "  DigitsImageMatrix=DigitDataset.reshape(42000,28,28)\n",
        "  DigitsImageMatrixRotatedByNinetyDegree=np.transpose(DigitsImageMatrix,(0,2,1))\n",
        "  return DigitsImageMatrix,DigitsImageMatrixRotatedByNinetyDegree\n",
        "############################# Create Model #######################################\n",
        "def CreateRNNModel(input_shape):\n",
        "  from keras.layers import Input,Bidirectional,LSTM,Concatenate,Dense,GlobalMaxPooling1D,Dropout\n",
        "  from keras.models import Model\n",
        "  # Left To Right\n",
        "  DigitImageLeftToRightInputData = Input(shape=input_shape)\n",
        "  DigitImageLeftToRightLSTM = Bidirectional(LSTM(units=20,return_sequences=True))\n",
        "  DigitImageLeftToRightLSTMHiddenUnits = DigitImageLeftToRightLSTM(DigitImageLeftToRightInputData)\n",
        "  DigitImageLeftToRightLSTMHiddenUnitsMaxPooled=GlobalMaxPooling1D()(DigitImageLeftToRightLSTMHiddenUnits)\n",
        "  # Top To Bottom\n",
        "  DigitImageTopToBottomInputData = Input(shape=input_shape)\n",
        "  DigitImageTopToBottomLSTM = Bidirectional(LSTM(units=20,return_sequences=True))\n",
        "  DigitImageTopToBottomLSTMHiddenUnits = DigitImageTopToBottomLSTM(DigitImageTopToBottomInputData)\n",
        "  DigitImageTopToBottomLSTMHiddenUnitsMaxPooled = GlobalMaxPooling1D()(DigitImageTopToBottomLSTMHiddenUnits)\n",
        "  # Concatenate Both the Hidden Units\n",
        "  concatenator=Concatenate(axis=1)\n",
        "  ConcatenatedHiddenUnits=concatenator([DigitImageLeftToRightLSTMHiddenUnitsMaxPooled, DigitImageTopToBottomLSTMHiddenUnitsMaxPooled])\n",
        "  # Apply Dense Layer\n",
        "  ANNHiddenLayer1=Dense(units=256,activation='relu',kernel_initializer='random_uniform')(ConcatenatedHiddenUnits)\n",
        "  X=Dropout(0.2)(ANNHiddenLayer1)\n",
        "  ANNHiddenLayer2=Dense(units=256,activation='relu',kernel_initializer='random_uniform')(X)\n",
        "  X=Dropout(0.2)(ANNHiddenLayer2)\n",
        "  output=Dense(units=10,activation='softmax',kernel_initializer='random_uniform')(X)\n",
        "  model=Model([DigitImageLeftToRightInputData,DigitImageTopToBottomInputData],output)\n",
        "  model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "############################# Train Model #######################################\n",
        "def TrainModel(DigitsDatasetLefttoRight,DigitsDatasetTopToBottom,labels,classifier,Epochs,BatchSize,ValidationSplit):\n",
        "  from keras.callbacks import ModelCheckpoint\n",
        "  SaveBestModel=ModelCheckpoint(filepath=BestClassiferModel,monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "  classifier.fit([DigitsDatasetLefttoRight,DigitsDatasetTopToBottom],labels,epochs=Epochs,batch_size=BatchSize,validation_split=ValidationSplit,callbacks=[SaveBestModel])\n",
        "############################# Read Dataset #######################################\n",
        "#!wget https://raw.githubusercontent.com/drsimonj/kaggle-digit-recognizer/master/data/train.csv\n",
        "import pandas as pd\n",
        "Dataset=pd.read_csv('train.csv')\n",
        "#Dataset=Dataset.sample(frac=1).reset_index(drop=True)# Shuffles Dataset\n",
        "Lables=Dataset.iloc[:,0].values\n",
        "Digits=Dataset.iloc[:,1:].values\n",
        "DigitsImageMatrix,DigitsImageMatrixRotatedByNinetyDegree=CreateMNISTDigitsMatrix(Digits)\n",
        "Classifier=CreateRNNModel(DigitsImageMatrix[0].shape)\n",
        "TrainModel(DigitsImageMatrix,DigitsImageMatrixRotatedByNinetyDegree,Lables,Classifier,30,128,0.2)\n",
        "             \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 33600 samples, validate on 8400 samples\n",
            "Epoch 1/30\n",
            "33600/33600 [==============================] - 56s 2ms/step - loss: 0.8204 - acc: 0.7307 - val_loss: 0.2929 - val_acc: 0.9107\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.91071, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 2/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.2455 - acc: 0.9248 - val_loss: 0.1813 - val_acc: 0.9410\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91071 to 0.94095, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 3/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.1730 - acc: 0.9470 - val_loss: 0.1462 - val_acc: 0.9525\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.94095 to 0.95250, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 4/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.1357 - acc: 0.9589 - val_loss: 0.1295 - val_acc: 0.9582\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.95250 to 0.95821, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 5/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.1178 - acc: 0.9637 - val_loss: 0.1208 - val_acc: 0.9582\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.95821 to 0.95821, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 6/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0982 - acc: 0.9701 - val_loss: 0.1009 - val_acc: 0.9669\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.95821 to 0.96690, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 7/30\n",
            "33600/33600 [==============================] - 53s 2ms/step - loss: 0.0877 - acc: 0.9736 - val_loss: 0.0937 - val_acc: 0.9692\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.96690 to 0.96917, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 8/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0805 - acc: 0.9758 - val_loss: 0.0985 - val_acc: 0.9682\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.96917\n",
            "Epoch 9/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0743 - acc: 0.9768 - val_loss: 0.1035 - val_acc: 0.9669\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.96917\n",
            "Epoch 10/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0667 - acc: 0.9795 - val_loss: 0.0791 - val_acc: 0.9751\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.96917 to 0.97512, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 11/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0617 - acc: 0.9812 - val_loss: 0.0835 - val_acc: 0.9735\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.97512\n",
            "Epoch 12/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0536 - acc: 0.9838 - val_loss: 0.0698 - val_acc: 0.9793\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.97512 to 0.97929, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 13/30\n",
            "33600/33600 [==============================] - 53s 2ms/step - loss: 0.0529 - acc: 0.9831 - val_loss: 0.0732 - val_acc: 0.9770\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.97929\n",
            "Epoch 14/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0487 - acc: 0.9851 - val_loss: 0.0703 - val_acc: 0.9776\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.97929\n",
            "Epoch 15/30\n",
            "33600/33600 [==============================] - 55s 2ms/step - loss: 0.0437 - acc: 0.9865 - val_loss: 0.0774 - val_acc: 0.9769\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.97929\n",
            "Epoch 16/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0419 - acc: 0.9870 - val_loss: 0.0661 - val_acc: 0.9782\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.97929\n",
            "Epoch 17/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0405 - acc: 0.9868 - val_loss: 0.0704 - val_acc: 0.9782\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.97929\n",
            "Epoch 18/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0369 - acc: 0.9879 - val_loss: 0.0782 - val_acc: 0.9768\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.97929\n",
            "Epoch 19/30\n",
            "33600/33600 [==============================] - 53s 2ms/step - loss: 0.0343 - acc: 0.9894 - val_loss: 0.0732 - val_acc: 0.9782\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.97929\n",
            "Epoch 20/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0337 - acc: 0.9886 - val_loss: 0.0730 - val_acc: 0.9789\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.97929\n",
            "Epoch 21/30\n",
            "33600/33600 [==============================] - 55s 2ms/step - loss: 0.0310 - acc: 0.9905 - val_loss: 0.0704 - val_acc: 0.9793\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.97929 to 0.97929, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 22/30\n",
            "33600/33600 [==============================] - 55s 2ms/step - loss: 0.0303 - acc: 0.9906 - val_loss: 0.0790 - val_acc: 0.9777\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.97929\n",
            "Epoch 23/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0274 - acc: 0.9910 - val_loss: 0.0661 - val_acc: 0.9824\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.97929 to 0.98238, saving model to BestClassiferModelLSTM.hdf5\n",
            "Epoch 24/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0757 - val_acc: 0.9785\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.98238\n",
            "Epoch 25/30\n",
            "33600/33600 [==============================] - 53s 2ms/step - loss: 0.0304 - acc: 0.9897 - val_loss: 0.0712 - val_acc: 0.9805\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.98238\n",
            "Epoch 26/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0228 - acc: 0.9924 - val_loss: 0.0752 - val_acc: 0.9804\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.98238\n",
            "Epoch 27/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0725 - val_acc: 0.9813\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.98238\n",
            "Epoch 28/30\n",
            "33600/33600 [==============================] - 55s 2ms/step - loss: 0.0199 - acc: 0.9935 - val_loss: 0.0649 - val_acc: 0.9819\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.98238\n",
            "Epoch 29/30\n",
            "33600/33600 [==============================] - 53s 2ms/step - loss: 0.0248 - acc: 0.9924 - val_loss: 0.0711 - val_acc: 0.9805\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.98238\n",
            "Epoch 30/30\n",
            "33600/33600 [==============================] - 54s 2ms/step - loss: 0.0182 - acc: 0.9939 - val_loss: 0.0824 - val_acc: 0.9806\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.98238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK0hW93gEUCk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}